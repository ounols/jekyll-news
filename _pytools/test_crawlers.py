#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í¬ë¡¤ëŸ¬ ë¡œì§ í…ŒìŠ¤íŠ¸ (ì˜¤í”„ë¼ì¸ ëª¨ë“œ)
- ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì—†ì´ í¬ë¡¤ëŸ¬ ë¡œì§ ê²€ì¦
- ìƒ˜í”Œ HTMLë¡œ íŒŒì‹± í…ŒìŠ¤íŠ¸
"""

import sys
from pathlib import Path
from datetime import datetime

# Windows ì½˜ì†” ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')


def test_imports():
    """í•„ìš”í•œ ëª¨ë“ˆ import í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("1. Import í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    modules = {
        'cloudscraper': False,
        'bs4': False,
        'readability': False,
        'deep_translator': False,
        'lxml': False,
    }

    try:
        import cloudscraper
        modules['cloudscraper'] = True
    except ImportError:
        pass

    try:
        from bs4 import BeautifulSoup
        modules['bs4'] = True
    except ImportError:
        pass

    try:
        from readability import Document
        modules['readability'] = True
    except ImportError:
        pass

    try:
        from deep_translator import GoogleTranslator
        modules['deep_translator'] = True
    except ImportError:
        pass

    try:
        import lxml
        modules['lxml'] = True
    except ImportError:
        pass

    for mod, status in modules.items():
        icon = "âœ…" if status else "âŒ"
        print(f"  {icon} {mod}")

    all_ok = all(modules.values())
    print(f"\nê²°ê³¼: {'ëª¨ë“  ëª¨ë“ˆ OK' if all_ok else 'ì¼ë¶€ ëª¨ë“ˆ ëˆ„ë½'}")
    return all_ok


def test_html_parsing():
    """HTML íŒŒì‹± í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("2. HTML íŒŒì‹± í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    from bs4 import BeautifulSoup

    # ìƒ˜í”Œ ë‰´ìŠ¤ HTML
    sample_html = """
    <html>
    <head><title>Stock Market News</title></head>
    <body>
        <article class="news-item">
            <h2 class="headline">NVIDIA Surges on AI Demand</h2>
            <p class="summary">NVIDIA stock rose 5% today amid strong AI chip demand.</p>
            <a href="/news/nvidia-ai-2024" class="link">Read more</a>
            <img src="/images/nvda.jpg" alt="NVIDIA">
        </article>
        <article class="news-item">
            <h2 class="headline">Apple Announces New iPhone</h2>
            <p class="summary">Apple unveiled the latest iPhone with advanced features.</p>
            <a href="/news/apple-iphone-2024" class="link">Read more</a>
        </article>
    </body>
    </html>
    """

    soup = BeautifulSoup(sample_html, 'lxml')
    articles = soup.find_all('article', class_='news-item')

    print(f"  ë°œê²¬ëœ ê¸°ì‚¬ ìˆ˜: {len(articles)}")

    for i, article in enumerate(articles, 1):
        title = article.find('h2').get_text(strip=True)
        summary = article.find('p').get_text(strip=True)
        link = article.find('a').get('href', '')
        print(f"  [{i}] {title}")
        print(f"      ë§í¬: {link}")

    return len(articles) == 2


def test_rss_parsing():
    """RSS íŒŒì‹± í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("3. RSS íŒŒì‹± í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    from bs4 import BeautifulSoup

    # ìƒ˜í”Œ RSS XML
    sample_rss = """<?xml version="1.0" encoding="UTF-8"?>
    <rss version="2.0">
        <channel>
            <title>Finance News</title>
            <item>
                <title>Tesla Stock Rises After Earnings</title>
                <link>https://example.com/tesla-earnings</link>
                <description>Tesla exceeded analyst expectations...</description>
            </item>
            <item>
                <title>Fed Signals Rate Cut</title>
                <link>https://example.com/fed-rate-cut</link>
                <description>Federal Reserve hints at interest rate reduction...</description>
            </item>
        </channel>
    </rss>
    """

    soup = BeautifulSoup(sample_rss, 'lxml-xml')
    items = soup.find_all('item')

    print(f"  ë°œê²¬ëœ RSS ì•„ì´í…œ ìˆ˜: {len(items)}")

    for i, item in enumerate(items, 1):
        title = item.find('title').get_text(strip=True)
        link = item.find('link').get_text(strip=True)
        print(f"  [{i}] {title}")
        print(f"      ë§í¬: {link}")

    return len(items) == 2


def test_ticker_extraction():
    """í‹°ì»¤ ì‹¬ë³¼ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("4. í‹°ì»¤ ì‹¬ë³¼ ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    import re

    sample_text = """
    NVIDIA ($NVDA) stock surged 5% today. Meanwhile, Apple (AAPL)
    and Microsoft (MSFT) also saw gains. Tesla stock price increased
    after the company reported strong earnings.
    """

    patterns = [
        r'\$([A-Z]{1,5})\b',
        r'\(([A-Z]{2,5})\)',
    ]

    tickers = set()
    for pattern in patterns:
        matches = re.findall(pattern, sample_text)
        tickers.update(matches)

    print(f"  ë°œê²¬ëœ í‹°ì»¤: {sorted(tickers)}")

    expected = {'NVDA', 'AAPL', 'MSFT'}
    return tickers == expected


def test_filename_sanitization():
    """íŒŒì¼ëª… ìƒì„± í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("5. íŒŒì¼ëª… ìƒì„± í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    import re

    def sanitize_filename(text):
        text = re.sub(r'[^\w\sã„±-ã…ã…-ã…£ê°€-í£-]', '', text)
        text = re.sub(r'[-\s]+', '-', text)
        return text.strip('-')[:80]

    test_cases = [
        ("NVIDIA's Stock Surges 5%!", "NVIDIAs-Stock-Surges-5"),
        ("ì• í”Œ, ìƒˆ ì•„ì´í° ë°œí‘œ", "ì• í”Œ-ìƒˆ-ì•„ì´í°-ë°œí‘œ"),
        ("Test   Multiple   Spaces", "Test-Multiple-Spaces"),
    ]

    all_pass = True
    for original, expected in test_cases:
        result = sanitize_filename(original)
        status = "âœ…" if result == expected else "âŒ"
        print(f"  {status} '{original}' -> '{result}'")
        if result != expected:
            print(f"      ì˜ˆìƒ: '{expected}'")
            all_pass = False

    return all_pass


def test_post_generation():
    """í¬ìŠ¤íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("6. í¬ìŠ¤íŠ¸ Front Matter ìƒì„± í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    title = "NVIDIA Stock Surges on AI Demand"
    date = datetime.now()
    excerpt = "NVIDIA stock rose 5% today..."

    # YAML escape
    title_escaped = title.replace("'", "''")
    excerpt_escaped = excerpt.replace("'", "''")

    front_matter = f"""---
layout: post
title: '{title_escaped}'
date: {date.strftime('%Y-%m-%d %H:%M:%S +0900')}
categories: [Financial]
author: "Test Source"
excerpt: '{excerpt_escaped}'
stock_tags:
  - symbol: NVDA
    instrument_id: 6497
---

Test content here.
"""

    print("  ìƒì„±ëœ Front Matter:")
    for line in front_matter.split('\n')[:10]:
        print(f"    {line}")

    # ê¸°ë³¸ ê²€ì¦
    has_layout = 'layout: post' in front_matter
    has_title = f"title: '{title}'" in front_matter
    has_category = 'categories: [Financial]' in front_matter

    print(f"\n  layout í¬í•¨: {'âœ…' if has_layout else 'âŒ'}")
    print(f"  title í¬í•¨: {'âœ…' if has_title else 'âŒ'}")
    print(f"  categories í¬í•¨: {'âœ…' if has_category else 'âŒ'}")

    return has_layout and has_title and has_category


def test_crawler_classes():
    """í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤ ë¡œë“œ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("7. í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤ ë¡œë“œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    crawlers = {}

    try:
        from investing_complete_kr import InvestingCompleteKR
        crawlers['Investing.com'] = True
    except Exception as e:
        crawlers['Investing.com'] = str(e)[:50]

    try:
        from yahoo_finance_kr import YahooFinanceKR
        crawlers['Yahoo Finance'] = True
    except Exception as e:
        crawlers['Yahoo Finance'] = str(e)[:50]

    try:
        from marketwatch_kr import MarketWatchKR
        crawlers['MarketWatch'] = True
    except Exception as e:
        crawlers['MarketWatch'] = str(e)[:50]

    try:
        from cnbc_kr import CNBCKR
        crawlers['CNBC'] = True
    except Exception as e:
        crawlers['CNBC'] = str(e)[:50]

    for name, status in crawlers.items():
        if status is True:
            print(f"  âœ… {name}")
        else:
            print(f"  âŒ {name}: {status}")

    return all(v is True for v in crawlers.values())


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("=" * 60)
    print("ğŸ§ª í¬ë¡¤ëŸ¬ ì˜¤í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    results = {
        'Import í…ŒìŠ¤íŠ¸': test_imports(),
        'HTML íŒŒì‹±': test_html_parsing(),
        'RSS íŒŒì‹±': test_rss_parsing(),
        'í‹°ì»¤ ì¶”ì¶œ': test_ticker_extraction(),
        'íŒŒì¼ëª… ìƒì„±': test_filename_sanitization(),
        'í¬ìŠ¤íŠ¸ ìƒì„±': test_post_generation(),
        'í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤': test_crawler_classes(),
    }

    print("\n" + "=" * 60)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)

    for test_name, passed in results.items():
        icon = "âœ…" if passed else "âŒ"
        print(f"  {icon} {test_name}")

    passed_count = sum(1 for v in results.values() if v)
    total_count = len(results)

    print("-" * 60)
    print(f"  ì´ {total_count}ê°œ ì¤‘ {passed_count}ê°œ í†µê³¼")

    if passed_count == total_count:
        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! í¬ë¡¤ëŸ¬ ë¡œì§ì´ ì •ìƒì…ë‹ˆë‹¤.")
        print("   ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ë©´ ì‘ë™í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.")
    else:
        print("\nâš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ìœ„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()
